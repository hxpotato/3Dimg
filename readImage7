import tensorflow as tf
import numpy as np
import os
import nibabel as nib
import threading
import tensorlayer as tl
import matplotlib.pyplot as plt
import scipy
from tensorlayer.prepro import *
import skimage.measure
import sklearn as sk
import sklearn.model_selection

from sklearn.preprocessing import LabelBinarizer

import cv2
from keras.layers import Flatten


from tensorflow.examples.tutorials.mnist import input_data
from PIL import Image

nib.Nifti1Header.quaternion_threshold= - np.finfo(np.float32).eps * 10 #relax limit
#training_data_path = '/home/dl/Disk/data/AAL/825_Subject_AD/rmwp1ADNI_002_S_0619_MR_MPR-R__GradWarp__N3_Br_20070411125307309_S15145_I48616.nii'
root_path = '/home/dl/Disk/data/825SubjectAAL/'
preserving_ratio = 0.25 #filter out 2d images containing <25%

def show_img(ori_img):
    plt.imshow(ori_img[:,:,25])
    plt.show()

def read_data(path):
    image_data = nib.load(path).get_data()
    return image_data

dataPath_list=[]
data_label=[]
dataImg_list=[]
def get_file_path(root_path):
    path_lists = os.listdir(root_path)
    for dir_file in path_lists:
        dir_file_path = os.path.join(root_path,dir_file)

        if os.path.isdir(dir_file_path):
           get_file_path(dir_file_path)

        else:
           data = read_data(dir_file_path)
           #data = data[:,:,25]
           data = np.array(data)
           data.resize((109, 109, 109), refcheck=False)
           dataPath_list.append(dir_file_path)
           dataImg_list.append(data)


           dataPath= os.path.dirname(dir_file_path)
           dataPath = dataPath.split('/')[-1]
           data_label.append(dataPath)


#read image
get_file_path(root_path)
train_img, test_img, train_label, test_label = sk.model_selection.train_test_split(dataImg_list, data_label, test_size=0.33, random_state=42)

lb = LabelBinarizer()
train_label = lb.fit_transform(train_label) # one-hot
test_label = lb.transform(test_label)

#train_img /= 255
#train_img /= 255


#
# import pickle
# f = open("le.pickle","wb")
# f.write(pickle.dumps(lb))
# f.close()


from keras import models
from keras import layers

train_img =np.array(train_img)
test_img =np.array(test_img)
print(train_img.shape)
#train_img.reshape((-1,109,109,109))

model = models.Sequential()
model.add(layers.Dense(16, activation='relu', input_shape=(109,109,109),name="input_layer"))
model.add(layers.Dense(16, activation='relu'))
model.add(Flatten())
#model.add(layers.Dense(5, activation='softmax'))
model.add(layers.Dense(4, activation='sigmoid'))

#model.summary()

model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
             # loss= 'categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(train_img,
                    train_label,
                    epochs=4,
                    batch_size=8,
                    validation_split=0.1)
#evaluate
results = model.evaluate(test_img,test_label)
print("evaluate: {}".format(results))
#model.predict(test_img)